import { useRef, useState, useEffect } from 'react';

import { Button, message, Layout, Select, Modal, Slider, Tooltip, Radio } from 'antd';
import {
  PhoneOutlined,
  PhoneFilled,
  SoundOutlined,
  SoundFilled,
  SettingOutlined,
} from '@ant-design/icons';
import {
  WsChatClient,
  WsChatEventNames,
  WsToolsUtils,
} from '@coze/api/ws-tools';
import {
  type CommonErrorEvent,
  type ConversationAudioTranscriptUpdateEvent,
} from '@coze/api';

import { AudioConfig, type AudioConfigRef } from '../../components/audio-config';

import './index.css';
import getConfig from '../../utils/config';
import ReceiveMessage from '../chat/receive-message';
import SentenceMessage, {
  type SentenceMessageRef,
} from '../chat/sentence-message';
import SendMessage from '../chat/send-message';

const { Content } = Layout;

type CallState = 'idle' | 'calling' | 'connected';

const localStorageKey = 'iot-toys';
const config = getConfig(localStorageKey);

// è·å–å›å¤æ¨¡å¼é…ç½®
const getReplyMode = (): 'stream' | 'sentence' =>
  localStorage.getItem('replyMode') === 'sentence' ? 'sentence' : 'stream';



const IoTToys = () => {
  const clientRef = useRef<WsChatClient>();
  const audioConfigRef = useRef<AudioConfigRef>(null);
  const sentenceMessageRef = useRef<SentenceMessageRef>(null);

  // çŠ¶æ€ç®¡ç†
  const [callState, setCallState] = useState<CallState>('idle');
  const [isConnecting, setIsConnecting] = useState(false);

  // éŸ³é¢‘é…ç½®çŠ¶æ€
  const [volume, setVolume] = useState(100);
  const [transcript, setTranscript] = useState('');
  const [inputDevices, setInputDevices] = useState<MediaDeviceInfo[]>([]);
  const [isConfigModalOpen, setIsConfigModalOpen] = useState(false);

  // å¯¹è¯æ¨¡å¼å’Œå›å¤æ¨¡å¼
  const [turnDetectionType, setTurnDetectionType] = useState('server_vad');
  const [replyMode, setReplyMode] = useState<'stream' | 'sentence'>(
    getReplyMode(),
  );

  // è·å–éŸ³é¢‘è®¾å¤‡
  const [selectedInputDevice, setSelectedInputDevice] = useState<string>('');

  // æŒ‰é”®è¯´è¯çŠ¶æ€
  const [isPressRecording, setIsPressRecording] = useState(false);
  const [recordingDuration, setRecordingDuration] = useState(0);
  const recordTimer = useRef<ReturnType<typeof setTimeout> | null>(null);
  const maxRecordingTime = 60; // æœ€å¤§å½•éŸ³æ—¶é•¿ï¼ˆç§’ï¼‰
  const [isCancelRecording, setIsCancelRecording] = useState(false);
  const startTouchY = useRef<number>(0);

  useEffect(() => {
    const getDevices = async () => {
      const devices = await WsToolsUtils.getAudioDevices();
      setInputDevices(devices.audioInputs);
      if (devices.audioInputs.length > 0) {
        setSelectedInputDevice(devices.audioInputs[0].deviceId);
      }
    };
    getDevices();
  }, []);

  // åˆå§‹åŒ–å®¢æˆ·ç«¯
  async function initClient() {
    const permission = await WsToolsUtils.checkDevicePermission();
    if (!permission.audio) {
      throw new Error('éœ€è¦éº¦å…‹é£è®¿é—®æƒé™');
    }

    if (!config.getPat()) {
      throw new Error('è¯·å…ˆé…ç½®ä¸ªäººè®¿é—®ä»¤ç‰Œ');
    }

    if (!config.getBotId()) {
      throw new Error('è¯·å…ˆé…ç½®æ™ºèƒ½ä½“ID');
    }

    const audioConfig = audioConfigRef.current?.getSettings();
    console.log('audioConfig', audioConfig);

    const client = new WsChatClient({
      token: config.getPat(),
      baseWsURL: config.getBaseWsUrl(),
      allowPersonalAccessTokenInBrowser: true,
      botId: config.getBotId(),
      debug: audioConfig?.debug,
      voiceId: config.getVoiceId(),
      workflowId: config.getWorkflowId() || undefined,
      aiDenoisingConfig: !audioConfig?.noiseSuppression
        ? {
            mode: audioConfig?.denoiseMode,
            level: audioConfig?.denoiseLevel,
            assetsPath:
              'https://lf3-static.bytednsdoc.com/obj/eden-cn/613eh7lpqvhpeuloz/websocket',
          }
        : undefined,
      audioCaptureConfig: {
        echoCancellation: audioConfig?.echoCancellation,
        noiseSuppression: audioConfig?.noiseSuppression,
        autoGainControl: audioConfig?.autoGainControl,
      },
      wavRecordConfig: {
        enableSourceRecord: false,
        enableDenoiseRecord: false,
      },
      deviceId: selectedInputDevice || undefined,
      audioMutedDefault: false,
      enableLocalLoopback: audioConfig?.isHuaweiMobile,
    });

    if (
      !audioConfig?.noiseSuppression &&
      !WsToolsUtils.checkDenoiserSupport()
    ) {
      message.info('å½“å‰æµè§ˆå™¨ä¸æ”¯æŒAIé™å™ª');
    }

    clientRef.current = client;

    // ç›‘å¬äº‹ä»¶
    handleMessageEvent();
  }

  // å¤„ç†æ¶ˆæ¯äº‹ä»¶
  const handleMessageEvent = () => {
    // é”™è¯¯å¤„ç†
    clientRef.current?.on(
      WsChatEventNames.SERVER_ERROR,
      (_: string, event: unknown) => {
        console.log('[iot-toys] error', event);
        message.error(
          `å‘ç”Ÿé”™è¯¯ï¼š${(event as CommonErrorEvent)?.data?.msg} logid: ${
            (event as CommonErrorEvent)?.detail.logid
          }`,
        );
        clientRef.current?.disconnect();
        clientRef.current = undefined;
        setCallState('idle');
      },
    );

    // å¤„ç†éŸ³é¢‘è½¬å½•æ›´æ–°äº‹ä»¶
    clientRef.current?.on(
      WsChatEventNames.CONVERSATION_AUDIO_TRANSCRIPT_UPDATE,
      (_, data) => {
        const event = data as ConversationAudioTranscriptUpdateEvent;
        if (event.data.content) {
          setTranscript(event.data.content);
        }
      },
    );
  };

  // å¼€å§‹é€šè¯
  const handleStartCall = async () => {
    try {
      setIsConnecting(true);
      setCallState('calling');

      if (!clientRef.current) {
        await initClient();
      }

      const chatUpdate: any = {
        event_type: 'chat.update',
        data: {
          input_audio: {
            format: 'pcm',
            codec: 'pcm',
            sample_rate: 48000,
          },
          output_audio: {
            codec: 'pcm',
            pcm_config: {
              sample_rate: 24000,
            },
            voice_id: config.getVoiceId(),
          },
          turn_detection: {
            type: turnDetectionType,
          },
          need_play_prologue: true,
        },
      };

      await clientRef.current?.connect({ chatUpdate });

      setCallState('connected');
      setIsConnecting(false);
      message.success('é€šè¯å·²è¿æ¥');
    } catch (error) {
      console.error(error);
      message.error(`è¿æ¥é”™è¯¯ï¼š${(error as Error).message}`);
      setIsConnecting(false);
      setCallState('idle');
    }
  };

  // æŒ‚æ–­é€šè¯
  const handleEndCall = async () => {
    if (clientRef.current) {
      await clientRef.current.disconnect();
      clientRef.current = undefined;
    }

    setCallState('idle');
    message.success('é€šè¯å·²ç»“æŸ');
  };

  // éŸ³é‡æ§åˆ¶
  const handleVolumeChange = (value: number) => {
    setVolume(value);
    if (clientRef.current) {
      clientRef.current.setPlaybackVolume(value / 100);
    }
  };

  // å¤„ç†æŒ‰ä½è¯´è¯æŒ‰é’®
  const handleVoiceButtonMouseDown = (
    e: React.MouseEvent | React.TouchEvent,
  ) => {
    if (
      callState === 'connected' &&
      clientRef.current &&
      turnDetectionType === 'client_interrupt'
    ) {
      startPressRecord(e);
    }
  };

  const handleVoiceButtonMouseUp = () => {
    if (isPressRecording && !isCancelRecording) {
      finishPressRecord();
    } else if (isPressRecording && isCancelRecording) {
      cancelPressRecord();
    }
  };

  const handleVoiceButtonMouseLeave = () => {
    if (isPressRecording) {
      cancelPressRecord();
    }
  };

  const handleVoiceButtonMouseMove = (
    e: React.MouseEvent | React.TouchEvent,
  ) => {
    if (isPressRecording && startTouchY.current) {
      // ä¸Šæ»‘è¶…è¿‡50pxåˆ™å–æ¶ˆå‘é€
      const clientY =
        'touches' in e ? e.touches[0].clientY : (e as React.MouseEvent).clientY;
      if (clientY < startTouchY.current - 50) {
        setIsCancelRecording(true);
      } else {
        setIsCancelRecording(false);
      }
    }
  };

  // å¼€å§‹æŒ‰é”®å½•éŸ³
  const startPressRecord = async (e: React.MouseEvent | React.TouchEvent) => {
    if (callState === 'connected' && clientRef.current) {
      try {
        // é‡ç½®å½•éŸ³çŠ¶æ€
        setIsPressRecording(true);
        setRecordingDuration(0);
        setIsCancelRecording(false);
        // Store initial touch position for determining sliding direction
        if ('clientY' in e) {
          startTouchY.current = (e as React.MouseEvent).clientY;
        } else if ('touches' in e && e.touches.length > 0) {
          startTouchY.current = e.touches[0].clientY;
        } else {
          startTouchY.current = 0;
        }

        // å¼€å§‹å½•éŸ³
        await clientRef.current.startRecord();

        // å¼€å§‹è®¡æ—¶
        recordTimer.current = setInterval(() => {
          setRecordingDuration(prev => {
            const newDuration = prev + 1;
            // è¶…è¿‡æœ€å¤§å½•éŸ³æ—¶é•¿è‡ªåŠ¨ç»“æŸ
            if (newDuration >= maxRecordingTime) {
              finishPressRecord();
            }
            return newDuration;
          });
        }, 1000);
      } catch (error: any) {
        message.error(`å¼€å§‹å½•éŸ³é”™è¯¯: ${error.message || 'æœªçŸ¥é”™è¯¯'}`);
        console.trace('å¼€å§‹å½•éŸ³é”™è¯¯:', error);
        // Clean up timer if it was set
        if (recordTimer.current) {
          clearInterval(recordTimer.current);
          recordTimer.current = null;
        }
        // Reset recording state
        setIsPressRecording(false);
        setRecordingDuration(0);
      }
    }
  };

  // ç»“æŸæŒ‰é”®å½•éŸ³å¹¶å‘é€
  const finishPressRecord = () => {
    if (isPressRecording && clientRef.current) {
      try {
        // åœæ­¢è®¡æ—¶
        if (recordTimer.current) {
          clearInterval(recordTimer.current);
          recordTimer.current = null;
        }

        // å¦‚æœå½•éŸ³æ—¶é—´å¤ªçŸ­ï¼ˆå°äº1ç§’ï¼‰ï¼Œè§†ä¸ºæ— æ•ˆ
        if (recordingDuration < 1) {
          cancelPressRecord();
          return;
        }

        // åœæ­¢å½•éŸ³å¹¶å‘é€
        clientRef.current.stopRecord();
        setIsPressRecording(false);

        // æ˜¾ç¤ºæç¤º
        message.success(`å‘é€äº† ${recordingDuration} ç§’çš„è¯­éŸ³æ¶ˆæ¯`);
      } catch (error: any) {
        message.error(`ç»“æŸå½•éŸ³é”™è¯¯: ${error.message || 'æœªçŸ¥é”™è¯¯'}`);
        console.error('ç»“æŸå½•éŸ³é”™è¯¯:', error);
      }
    }
  };

  // å–æ¶ˆæŒ‰é”®å½•éŸ³
  const cancelPressRecord = async () => {
    if (isPressRecording && clientRef.current) {
      try {
        // åœæ­¢è®¡æ—¶
        if (recordTimer.current) {
          clearInterval(recordTimer.current);
          recordTimer.current = null;
        }

        // å–æ¶ˆå½•éŸ³
        await clientRef.current?.stopRecord();
        setIsPressRecording(false);
        setIsCancelRecording(false);

        // æ˜¾ç¤ºæç¤º
        message.info('å–æ¶ˆäº†è¯­éŸ³æ¶ˆæ¯');
      } catch (error: any) {
        message.error(`å–æ¶ˆå½•éŸ³é”™è¯¯: ${error.message || 'æœªçŸ¥é”™è¯¯'}`);
        console.error('å–æ¶ˆå½•éŸ³é”™è¯¯:', error);
      }
    }
  };

  // æ¸…ç†èµ„æº
  useEffect(() => {
    return () => {
      if (recordTimer.current) {
        clearInterval(recordTimer.current);
      }
      if (clientRef.current) {
        clientRef.current.disconnect();
      }
    };
  }, []);

  // æ¸²æŸ“åˆå§‹çŠ¶æ€ç•Œé¢
  const renderIdleState = () => (
    <div className="hero-section">
      <h1>ç”Ÿæ´»ç‰©è”ç½‘ AI ç©å…·æ¼”ç¤ºå¹³å°</h1>
      <p>ä½“éªŒæ™ºèƒ½å¯¹è¯ï¼Œå¼€å¯ç‰©è”ç½‘æ–°æ—¶ä»£</p>
      <div className="button-group">
        <Button
          type="primary"
          icon={<SettingOutlined />}
          onClick={() => setIsConfigModalOpen(true)}
          style={{ marginBottom: 20 }}
        >
          é…ç½®
        </Button>
      </div>
      <button className="call-button" onClick={handleStartCall}>
        <span className="phone-icon"><PhoneOutlined /></span>
        <span className="button-text">å¼€å§‹å¯¹è¯</span>
      </button>
    </div>
  );

  // æ¸²æŸ“é€šè¯ä¸­ç•Œé¢
  const renderCallingState = () => (
    <div className="calling-section">
      {isConnecting ? (
        <div className="loading-container">
          <div className="loading-ring"></div>
          <div className="loading-text">æ­£åœ¨è¿æ¥ AI ç©å…·...</div>
        </div>
      ) : (
        <>
          <div className="call-header">
            <div className="call-status">
              <span className="status-dot"></span>
              <span>é€šè¯ä¸­</span>
            </div>
            <div className="header-actions">
              <div className="mode-selector">
                <Tooltip title="é€‰æ‹©å¯¹è¯æ¨¡å¼">
                  <Radio.Group
                    value={turnDetectionType}
                    onChange={e => setTurnDetectionType(e.target.value)}
                    size="small"
                  >
                    <Radio.Button value="server_vad">è‡ªåŠ¨æ£€æµ‹</Radio.Button>
                    <Radio.Button value="client_interrupt">æŒ‰é”®è¯´è¯</Radio.Button>
                  </Radio.Group>
                </Tooltip>
              </div>
              <div className="mode-selector" style={{ marginLeft: '8px' }}>
                <Tooltip title="é€‰æ‹©å›å¤æ¨¡å¼">
                  <Radio.Group
                    value={replyMode}
                    onChange={e => {
                      setReplyMode(e.target.value);
                      localStorage.setItem('replyMode', e.target.value);
                    }}
                    size="small"
                  >
                    <Radio.Button value="stream">æµå¼</Radio.Button>
                    <Radio.Button value="sentence">éŸ³å­—åŒæ­¥</Radio.Button>
                  </Radio.Group>
                </Tooltip>
              </div>
              <Button
                type="text"
                icon={<SettingOutlined />}
                onClick={() => setIsConfigModalOpen(true)}
                className="config-btn"
              >
                é…ç½®
              </Button>
            </div>
          </div>

          <div className="assistant-avatar">ğŸ¤–</div>

          {/* å‘é€æ–‡æœ¬æ¶ˆæ¯ */}
          <SendMessage
            isConnected={callState === 'connected'}
            clientRef={clientRef}
            onSendText={(text: string) => {
              sentenceMessageRef.current?.addMessage(text);
            }}
          />

          {/* æ˜¾ç¤ºå®æ—¶è¯†åˆ«ç»“æœ */}
          <div style={{ margin: '16px 0' }}>
            è¯­éŸ³è¯†åˆ«ç»“æœï¼š{transcript}
          </div>

          {/* æŒ‰é”®è¯´è¯åŠŸèƒ½åŒº */}
          {turnDetectionType === 'client_interrupt' && callState === 'connected' && (
            <div style={{ maxWidth: '400px', margin: '0 auto 16px' }}>
              <div
                className={`voice-button ${isPressRecording ? 'recording' : ''}`}
                onMouseDown={handleVoiceButtonMouseDown}
                onMouseUp={handleVoiceButtonMouseUp}
                onMouseLeave={handleVoiceButtonMouseLeave}
                onMouseMove={handleVoiceButtonMouseMove}
                onTouchStart={handleVoiceButtonMouseDown}
                onTouchEnd={handleVoiceButtonMouseUp}
                onTouchCancel={handleVoiceButtonMouseLeave}
                onTouchMove={handleVoiceButtonMouseMove}
              >
                {isPressRecording ? 'æ¾å¼€ å‘é€' : 'æŒ‰ä½ è¯´è¯'}
              </div>

              {/* å½•éŸ³çŠ¶æ€æç¤º */}
              {isPressRecording && (
                <div className="recording-status">
                  <div className="recording-time">
                    {Math.floor(recordingDuration / 60)
                      .toString()
                      .padStart(2, '0')}
                    :{(recordingDuration % 60).toString().padStart(2, '0')}
                  </div>
                  <div className="recording-progress-container">
                    <div
                      className="recording-progress"
                      style={{
                        width: `${(recordingDuration / maxRecordingTime) * 100}%`,
                      }}
                    ></div>
                  </div>
                  <div
                    className={`recording-tip ${isCancelRecording ? 'cancel-tip' : ''}`}
                  >
                    {isCancelRecording ? 'æ¾å¼€æ‰‹æŒ‡ï¼Œå–æ¶ˆå‘é€' : 'ä¸Šæ»‘å–æ¶ˆå‘é€'}
                  </div>
                </div>
              )}
            </div>
          )}

          {/* æ ¹æ®å›å¤æ¨¡å¼é€‰æ‹©å¯¹åº”çš„æ¶ˆæ¯ç»„ä»¶ */}
          {replyMode === 'stream' ? (
            <ReceiveMessage clientRef={clientRef} />
          ) : (
            <SentenceMessage ref={sentenceMessageRef} clientRef={clientRef} />
          )}

          <div className="control-panel">
            {/* éŸ³é‡æ§åˆ¶ */}
            <div className="volume-control">
              <Tooltip title={`éŸ³é‡: ${volume}%`}>
                <div className="volume-icon">
                  {volume > 0 ? <SoundFilled /> : <SoundOutlined />}
                </div>
              </Tooltip>
              <Slider
                min={0}
                max={100}
                value={volume}
                onChange={handleVolumeChange}
                className="volume-slider"
              />
              <span className="volume-value">{volume}%</span>
            </div>

            {/* è¾“å…¥è®¾å¤‡é€‰æ‹© */}
            <Select
              placeholder="é€‰æ‹©éº¦å…‹é£"
              value={selectedInputDevice}
              onChange={setSelectedInputDevice}
              className="device-select"
              suffixIcon={<SoundOutlined />}
            >
              {inputDevices.map(device => (
                <Select.Option key={device.deviceId} value={device.deviceId}>
                  {device.label}
                </Select.Option>
              ))}
            </Select>
          </div>

          <div className="control-buttons">
            <button className="btn-hangup" onClick={handleEndCall}>
              <span><PhoneFilled /></span>
            </button>
          </div>
        </>
      )}
    </div>
  );

  return (
    <Layout className="iot-toys-page">
      <Content className="iot-toys-container">
        {callState === 'idle' && renderIdleState()}
        {callState === 'calling' && renderCallingState()}
        {callState === 'connected' && renderCallingState()}
      </Content>

      {/* éŸ³é¢‘é…ç½®æ¨¡æ€æ¡† */}
      <Modal
        title="éŸ³é¢‘é…ç½®"
        open={isConfigModalOpen}
        onCancel={() => setIsConfigModalOpen(false)}
        footer={[
          <Button key="close" onClick={() => setIsConfigModalOpen(false)}>
            å…³é—­
          </Button>,
        ]}
        width={600}
        className="audio-config-modal"
      >
        <AudioConfig clientRef={clientRef} ref={audioConfigRef} />
      </Modal>
    </Layout>
  );
};

export default IoTToys;
